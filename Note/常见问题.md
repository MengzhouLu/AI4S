# 翻墙问题：

**OSError: Can't load tokenizer for 'bert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'bert-base-uncased' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.**

解决方法：HF_ENDPOINT=https://hf-mirror.com python3 blip2_qformer.py



GIT clone 失败：(这个方法有一个弊端，无法提交)

​	git clone https://mirror.ghproxy.com/https://github.com/USERNAME/REPOSITORY



# 多GPU训练问题：

[pytorch 并行训练之DistributedDataParallel（代码样例和解释） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/350301395)

[关于集群分布式torchrun命令踩坑记录（自用）-CSDN博客](https://blog.csdn.net/Komach/article/details/130765773)

torchrun --nproc_per_node=1 train_mymodel.py（nproc_per_node即GPU数量）

# GPU占用问题：

过高：混合精度训练

低：设置dataloader：![7f382ca37634c129b8654b97d778f8b7.jpeg](https://i-blog.csdnimg.cn/blog_migrate/c1a4c73a4047daf4f6d664f4926574e6.jpeg)

# 多数据集训练问题

怎么用：

**Batch_size和learning rate:**DDP中

​	首先明确没有前缀的batch size通常是指单卡的batch size，对于多机多卡有效batch size（effective batch size）=节点数* 每节点卡数* 单卡batch size*梯度累计步数。（**如单卡BZ=32,DDP4卡，则有效BZ=32 *4=128**）

​	现在假设在单卡环境下训练某个模型使用的batch size=32，lr=0.01。这时在4卡环境想重复这个实验，该如何设置batch size和lr呢？简单的回答是，在pytorch或者lightning中，需要将给data_loader的batch_size设为32/4=8，而lr保持不变为0.01。(**这样在主进程上tqdm显示的epoch数实际没有变化，因为DDP4卡时数据会拆成4份，每个GPU只拿到了原先单卡时1/4的数据，而bz也正好设置为了原先的1/4；那么在epoch数实际没有变化时，lr不需要改变**)

​	如果保持BZ=32,则有效BZ=32 *4=128，在主进程上tqdm显示的epoch数为单卡时1/4，所以lr要随之线性增长（或者平方根增长）

​	**注意，如果epoch总数很少，但是一个epoch中batch很多，那么学习率的更新就不应该在每个epoch中，应该在每个batch中**

# LINUX

screen下按Ctrl+a，再按ESC即可翻页

# Token

openai经验:一个有用的经验法则是，对于常见的英语文本，一个标记通常对应于 ~4 个字符的文本。这大约相当于一个单词的 3/4（所以 100 个标记 ~= 75 个单词）。

https://platform.openai.com/tokenizer
